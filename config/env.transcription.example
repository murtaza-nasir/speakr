# =============================================================================
# Transcription Connector Configuration
# =============================================================================
#
# Speakr supports multiple transcription providers through a connector-based
# architecture. This file documents all available configuration options.
#
# Quick Start (Simplified):
# 1. For OpenAI with diarization: Set TRANSCRIPTION_MODEL=gpt-4o-transcribe-diarize
# 2. For self-hosted ASR: Set ASR_BASE_URL=http://your-asr:9000
# 3. For legacy Whisper: Set TRANSCRIPTION_API_KEY and optionally TRANSCRIPTION_MODEL
#
# Auto-Detection Priority:
# 1. TRANSCRIPTION_CONNECTOR - explicit connector name (if you need full control)
# 2. ASR_BASE_URL - if set, uses ASR endpoint connector
# 3. TRANSCRIPTION_MODEL contains 'gpt-4o' - uses OpenAI Transcribe connector
# 4. Default - uses OpenAI Whisper connector with TRANSCRIPTION_MODEL or whisper-1

# =============================================================================
# CONNECTOR SELECTION (Auto-detected if not set)
# =============================================================================
# Options: openai_whisper, openai_transcribe, asr_endpoint
# Leave empty to auto-detect based on other settings
# TRANSCRIPTION_CONNECTOR=

# Feature flag to enable/disable new connector architecture (default: true)
# Set to false to use legacy code path for troubleshooting
# USE_NEW_TRANSCRIPTION_ARCHITECTURE=true

# =============================================================================
# OPENAI CONFIGURATION (Required for openai_whisper and openai_transcribe)
# =============================================================================
TRANSCRIPTION_API_KEY=your_openai_api_key
TRANSCRIPTION_BASE_URL=https://api.openai.com/v1

# Model Selection - determines which connector is used:
#
# whisper-1              - Legacy Whisper model, no diarization, $0.006/min
#                          Supports: srt, vtt, json, verbose_json output formats
#
# gpt-4o-transcribe      - High quality transcription, no diarization, $0.006/min
#                          Better accuracy than whisper-1, accepts prompts
#
# gpt-4o-mini-transcribe - Cost-effective option, no diarization, $0.003/min
#                          Good for high-volume, budget-conscious use
#
# gpt-4o-transcribe-diarize - Speaker diarization!, $0.006/min
#                             Identifies speakers as A, B, C, D...
#                             Requires chunking_strategy for audio >30s
#
TRANSCRIPTION_MODEL=gpt-4o-transcribe-diarize

# Legacy Whisper model name (used when TRANSCRIPTION_MODEL is not set)
# WHISPER_MODEL=whisper-1

# =============================================================================
# ASR ENDPOINT CONFIGURATION (For self-hosted whisper services)
# =============================================================================
# Note: USE_ASR_ENDPOINT is deprecated. Just set ASR_BASE_URL instead.
# The connector will auto-detect ASR mode when ASR_BASE_URL is set.
# USE_ASR_ENDPOINT=true  # Deprecated - kept for backwards compatibility

# Base URL of your ASR service (required if USE_ASR_ENDPOINT=true)
# Supports: whisper-asr-webservice, WhisperX, and compatible services
# ASR_BASE_URL=http://whisper-asr:9000

# Request timeout in seconds (default: 1800 = 30 minutes)
# Increase for very long audio files
# ASR_TIMEOUT=1800

# Enable speaker diarization (default: true)
# ASR_DIARIZE=true

# Speaker count hints (optional, helps with diarization accuracy)
# ASR_MIN_SPEAKERS=1
# ASR_MAX_SPEAKERS=5

# Return speaker embeddings for speaker identification (WhisperX only)
# Enables automatic speaker matching across recordings
# ASR_RETURN_SPEAKER_EMBEDDINGS=false

# =============================================================================
# CHUNKING CONFIGURATION (For large files)
# =============================================================================
# Enable automatic file chunking for large audio files
ENABLE_CHUNKING=true

# Maximum chunk size in MB (files larger than this will be split)
CHUNK_SIZE_MB=20

# Overlap between chunks in seconds (helps with transcription accuracy at boundaries)
CHUNK_OVERLAP_SECONDS=3

# =============================================================================
# EXAMPLE CONFIGURATIONS (Simplified)
# =============================================================================
#
# --- OpenAI with Speaker Diarization (Recommended) ---
# Just two environment variables needed:
# TRANSCRIPTION_API_KEY=sk-xxx
# TRANSCRIPTION_MODEL=gpt-4o-transcribe-diarize
#
# --- Self-hosted WhisperX (Best for privacy) ---
# Just one environment variable needed (auto-detects ASR mode):
# ASR_BASE_URL=http://whisper-asr:9000
# Optional:
# ASR_DIARIZE=true
# ASR_RETURN_SPEAKER_EMBEDDINGS=true
#
# --- OpenAI Whisper (Legacy, no diarization) ---
# TRANSCRIPTION_API_KEY=sk-xxx
# TRANSCRIPTION_MODEL=whisper-1
#
# --- Custom Whisper model (local or compatible endpoint) ---
# TRANSCRIPTION_API_KEY=not-needed
# TRANSCRIPTION_BASE_URL=http://localhost:8080/v1
# TRANSCRIPTION_MODEL=Systran/faster-distil-whisper-large-v3

# =============================================================================
# FUTURE: Additional Provider Notes
# =============================================================================
# The connector architecture is designed to support additional providers.
# Future connectors may include:
#
# - Deepgram: Known for excellent diarization and real-time transcription
# - AssemblyAI: Strong diarization with speaker labels
# - Google Cloud Speech-to-Text: Enterprise-grade with speaker diarization
#
# To request a new connector, please open an issue on GitHub.
