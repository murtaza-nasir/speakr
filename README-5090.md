# ğŸ™ï¸ Speakr + ASR Whisperï¼ˆrtx 5090 supportï¼‰ æœ¬åœ°ç¦»çº¿è¯­éŸ³è½¬å†™ç³»ç»Ÿéƒ¨ç½²æŒ‡å—

æœ¬é¡¹ç›®é›†æˆäº† [Speakr](https://github.com/learnedmachine/speakr) å’Œ [Asr-webservice](https://github.com/ahmetoner/whisper-asr-webservice)ï¼Œå®ç°äº†åŸºäº Whisper çš„æœ¬åœ°ç¦»çº¿éŸ³é¢‘è½¬å†™åŠŸèƒ½ï¼Œæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡å½•éŸ³çš„è½¬å†™ï¼Œå¹¶æä¾›ç½‘é¡µç«¯ç•Œé¢ï¼ŒåŒæ—¶asræœåŠ¡é¢å¤–æ·»åŠ äº†å¯¹äºRTX 5090æ˜¾å¡çš„æ”¯æŒï¼ˆtorch2.7+cuda128ï¼‰ã€‚

## æ”¯æŒ5090æ˜¾å¡ï¼Œæ”¯æŒäººç‰©è§’è‰²åˆ†ç¦»ï¼Œå¯¹äºä¸­æ–‡ï¼Œæ¨èä½¿ç”¨large-v3æ¨¡å‹ï¼Œå‡†ç¡®ç‡æ›´é«˜

## ğŸ“¦ é¡¹ç›®ç»“æ„

â”œâ”€speakr_whisperx
â”‚  â”œâ”€huggingface
â”‚  â”‚  â””â”€hub
â”‚  â”‚      â”œâ”€models--jonatasgrosman--wav2vec2-large-xlsr-53-chinese-zh-cn
â”‚  â”‚      â”‚  â”œâ”€.no_exist
â”‚  â”‚      â”‚  â”‚  â””â”€99ccb2737be22b8bb50dcfcc39ad4d567fb90cfd
â”‚  â”‚      â”‚  â”œâ”€blobs
â”‚  â”‚      â”‚  â”œâ”€refs
â”‚  â”‚      â”‚  â””â”€snapshots
â”‚  â”‚      â”‚      â””â”€99ccb2737be22b8bb50dcfcc39ad4d567fb90cfd
â”‚  â”‚      â”‚          â””â”€.cache
â”‚  â”‚      â”‚              â””â”€huggingface
â”‚  â”‚      â”‚                  â””â”€download
â”‚  â”‚      â”œâ”€models--pyannote--segmentation-3.0
â”‚  â”‚      â”‚  â””â”€.cache
â”‚  â”‚      â”‚      â””â”€huggingface
â”‚  â”‚      â”‚          â””â”€download
â”‚  â”‚      â”œâ”€models--pyannote--speaker-diarization-3.1
â”‚  â”‚      â”‚  â”œâ”€.cache
â”‚  â”‚      â”‚  â”‚  â””â”€huggingface
â”‚  â”‚      â”‚  â”‚      â””â”€download
â”‚  â”‚      â”‚  â”‚          â”œâ”€.github
â”‚  â”‚      â”‚  â”‚          â”‚  â””â”€workflows
â”‚  â”‚      â”‚  â”‚          â””â”€reproducible_research
â”‚  â”‚      â”‚  â”œâ”€.github
â”‚  â”‚      â”‚  â”‚  â””â”€workflows
â”‚  â”‚      â”‚  â””â”€reproducible_research
â”‚  â”‚      â”œâ”€models--Systran--faster-whisper-large-v3
â”‚  â”‚      â”‚  â”œâ”€blobs
â”‚  â”‚      â”‚  â”œâ”€refs
â”‚  â”‚      â”‚  â””â”€snapshots
â”‚  â”‚      â”‚      â””â”€edaa852ec7e145841d8ffdb056a99866b5f0a478
â”‚  â”‚      â””â”€models--Systran--faster-whisper-medium
â”‚  â”‚          â”œâ”€blobs
â”‚  â”‚          â”œâ”€refs
â”‚  â”‚          â””â”€snapshots
â”‚  â”‚              â””â”€08e178d48790749d25932bbc082711ddcfdfbc4f
â”‚  â”œâ”€instance
â”‚  â”œâ”€models
â”‚  â””â”€uploads
â”‚  â””â”€docker-compose.yml

```yml
services:
  whisper-asr-webservice6002:    
    image: crpi-n9jif4z5nex2rnkd.cn-hangzhou.personal.cr.aliyuncs.com/docker_2025-images/whisper-asr-webservice_for_5090:latest
    container_name: whisper-asr-webservice6002
    ports:
      - "6002:9000"
    volumes:
      - ./huggingface/hub:/root/.cache/huggingface/hub
    environment:
      - ASR_MODEL=large-v3  # å¯é€‰ large-v3ã€mediumã€distil-large-v3(ä¸æ”¯æŒä¸­æ–‡)
      - ASR_COMPUTE_TYPE=fp16 # å¯é€‰ fp16ã€int8
      - ASR_ENGINE=whisperx
      - HF_TOKEN=hf_your_huggingface_token_here
      - HF_ENDPOINT=https://hf-mirror.com
      - HF_HOME=/root/.cache/huggingface/
    deploy:
      resources:
        limits:
          memory: 12G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia
    restart: always
    networks:
      - speakr-network

  app:
    image: learnedmachine/speakr:latest
    container_name: speakr8890
    restart: always
    ports:
      - "8890:8899"
    environment:
      - TEXT_MODEL_BASE_URL=http://100.64.0.16:11434/v1
      - TEXT_MODEL_API_KEY=your_api_key_here # ollamaçš„è¯è¿™é‡Œéšæ„å¡«å†™
      - TEXT_MODEL_NAME=qwen2.5:14b
      - USE_ASR_ENDPOINT=true

      - ASR_BASE_URL=http://100.64.0.16:6002
      # - ASR_BASE_URL=http://whisper-asr-webservice6002:9000 # Speakrä½œè€…æ¨èè¿™æ ·ä½¿ç”¨ï¼Œä½†æˆ‘æœ¬åœ°å®é™…æµ‹è¯•è¿™æ ·å’Œasræ— æ³•é€šä¿¡ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆ
      # é¡¹ç›®è¿è¡Œåï¼Œè®°å¾—åœ¨Speakrå‰å°adminç•Œé¢ä¿®æ”¹timeoutè¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤ä¸º30åˆ†é’Ÿï¼Œæˆ‘è®¾ç½®ä¸º180åˆ†é’Ÿ
      - ASR_ENCODE=true
      - ASR_TASK=transcribe
      - ASR_DIARIZE=true
      - ASR_MIN_SPEAKERS=1
      - ASR_MAX_SPEAKERS=5

      - ALLOW_REGISTRATION=false
      - SUMMARY_MAX_TOKENS=8000
      - CHAT_MAX_TOKENS=5000

      # Large File Chunking Configuration (for endpoints with file size limits like OpenAI)
      # Enable automatic chunking for large files that exceed API limits
      - ENABLE_CHUNKING=true
      - CHUNK_SIZE_MB=20

      # Overlap between chunks in seconds to ensure no speech is lost at boundaries
      # Recommended: 3-5 seconds for natural speech
      - CHUNK_OVERLAP_SECONDS=3

      - ADMIN_USERNAME=admin
      - ADMIN_EMAIL=admin@alt.org
      - ADMIN_PASSWORD=11111111

      # --- Automated File Processing (Black Hole Directory) ---
      # Set to "true" to enable automated file processing
      - ENABLE_AUTO_PROCESSING=false

      # Processing mode: admin_only, user_directories, or single_user
      - AUTO_PROCESS_MODE=admin_only

      # Directory to watch for new audio files
      - AUTO_PROCESS_WATCH_DIR=/auto-process

      # How often to check for new files (seconds)
      - AUTO_PROCESS_CHECK_INTERVAL=60

      # Default username for single_user mode (only used if AUTO_PROCESS_MODE=single_user)
      # AUTO_PROCESS_DEFAULT_USERNAME=admin

      - SQLALCHEMY_DATABASE_URI=sqlite:////data/instance/transcriptions.db
      - UPLOAD_FOLDER=/data/uploads
      
      - MAX_CONTENT_LENGTH=2621440000  # 2500*1024*1024
      - UPLOAD_LIMIT=2147483648
      - MAX_UPLOAD_SIZE=2147483648
    volumes:
      - ./uploads:/data/uploads
      - ./instance:/data/instance
    depends_on:
      - whisper-asr-webservice6002
    networks:
      - speakr-network

networks:
  speakr-network:
    driver: bridge
```
### æ¨¡å‹ä¸‹è½½ä»£ç 
```
# è®¾ç½®é•œåƒç¯å¢ƒå˜é‡ï¼ˆWindows PowerShellï¼‰
$env:HF_ENDPOINT = "https://hf-mirror.com"

# åœ¨æœ¬åœ°ç”µè„‘ä¸Šç›´æ¥ä½¿ç”¨ huggingface-cli ä¸‹è½½
huggingface-cli download --resume-download jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn --cache-dir D:/models/models--jonatasgrosman--wav2vec2-large-xlsr-53-chinese-zh-cn

# https://hf-mirror.com/jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn/tree/main


# è®¾ç½®é•œåƒç¯å¢ƒå˜é‡ï¼ˆWindows PowerShellï¼‰
$env:HF_ENDPOINT = "https://hf-mirror.com"

huggingface-cli download --resume-download openai/whisper-medium --cache-dir D:/models/models--openai--whisper-medium
# https://hf-mirror.com/openai/whisper-medium/tree/main

huggingface-cli download --resume-download Systran/faster-whisper-medium --cache-dir D:/models/models--Systran-faster-whisper-medium
# https://hf-mirror.com/Systran/faster-whisper-medium


huggingface-cli download --resume-download Systran/faster-whisper-large-v3 --cache-dir D:/models/models--Systran--faster-whisper-large-v3

# https://hf-mirror.com/Systran/faster-whisper-large-v3

ä»¥ä¸‹ä¸¤ä¸ªæ¨¡å‹éœ€è¦å…ˆåœ¨huggingfaceå®˜ç½‘æ³¨å†Œè´¦å·å¹¶è·å–tokenåæ‰èƒ½ä¸‹è½½ï¼Œå¹¶ä¸”åœ¨huggingfaceæ¨¡å‹ä¸»é¡µçš„model cardé‡Œå¡«å†™åç§°å’Œç½‘ç«™ä¿¡æ¯
https://huggingface.co/pyannote/speaker-diarization-3.1
https://huggingface.co/pyannote/segmentation-3.0


huggingface-cli download --token hf_your_huggingface_token_here --resume-download pyannote/speaker-diarization-3.1 --cache-dir D:/models/models--pyannote-speaker-diarization-3.1

huggingface-cli download --token hf_your_huggingface_token_here --resume-download pyannote/segmentation-3.0 --cache-dir D:/models/models--pyannote-segmentation-3.0
```
## ğŸ™Œ é¸£è°¢

- [Speakr](https://github.com/murtaza-nasir/speakr)
- [Asr-webservice](https://github.com/ahmetoner/whisper-asr-webservice)
- [Whisper](https://github.com/openai/whisper)
